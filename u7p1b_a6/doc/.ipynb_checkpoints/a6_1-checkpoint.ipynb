{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 340 Assignment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.sparse import csr_matrix as sparse_matrix\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "rubric={mechanics:5}\n",
    "\n",
    "\n",
    "The above points are allocated for following the [homework submission instructions](https://github.ugrad.cs.ubc.ca/CPSC340-2017W-T2/home/blob/master/homework_instructions.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Finding similar items\n",
    "\n",
    "For this question we'll be using the [Amazon product data set](http://jmcauley.ucsd.edu/data/amazon/). The author of the data set has asked for the following citations:\n",
    "\n",
    "> Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering.\n",
    "> R. He, J. McAuley.\n",
    "> WWW, 2016.\n",
    "> \n",
    "> Image-based recommendations on styles and substitutes.\n",
    "> J. McAuley, C. Targett, J. Shi, A. van den Hengel.\n",
    "> SIGIR, 2015.\n",
    "\n",
    "We will focus on the \"Patio, Lawn, and Garden\" section. Download the [ratings](http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Patio_Lawn_and_Garden.csv) and place the file in the `data` directory with the original filename. Once you do that, the code below should load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2VNYWOPJ13AFP</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1259798400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A20DWVV8HML3AW</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1371081600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3RVP3YBYYOPRH</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1257984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A28XY55TP3Q90O</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1314144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3VZW1BGUQO0V3</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1308268800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user        item  rating   timestamp\n",
       "0  A2VNYWOPJ13AFP  0981850006     5.0  1259798400\n",
       "1  A20DWVV8HML3AW  0981850006     5.0  1371081600\n",
       "2  A3RVP3YBYYOPRH  0981850006     5.0  1257984000\n",
       "3  A28XY55TP3Q90O  0981850006     5.0  1314144000\n",
       "4  A3VZW1BGUQO0V3  0981850006     5.0  1308268800"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"ratings_Patio_Lawn_and_Garden.csv\"\n",
    "\n",
    "with open(os.path.join(\"..\", \"data\", filename), \"rb\") as f:\n",
    "    ratings = pd.read_csv(f,names=(\"user\",\"item\",\"rating\",\"timestamp\"))\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd also like to construct the user-product matrix `X`. Let's see how big it would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 993490\n",
      "The average rating: 4.006400668350965\n",
      "Number of users: 714791\n",
      "Number of items: 105984\n",
      "Fraction nonzero: 1.3114269915944552e-05\n",
      "Size of full X matrix: 606.05 GB\n"
     ]
    }
   ],
   "source": [
    "def get_stats(ratings, item_key=\"item\", user_key=\"user\"):\n",
    "    print(\"Number of ratings:\", len(ratings))\n",
    "    print(\"The average rating:\", np.mean(ratings[\"rating\"]))\n",
    "\n",
    "    d = len(set(ratings[item_key]))\n",
    "    n = len(set(ratings[user_key]))\n",
    "    print(\"Number of users:\", n)\n",
    "    print(\"Number of items:\", d)\n",
    "    print(\"Fraction nonzero:\", len(ratings)/(n*d))\n",
    "    print(\"Size of full X matrix: %.2f GB\" % ((n*d)*8/1e9))\n",
    "\n",
    "    return n,d\n",
    "\n",
    "n,d = get_stats(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "600 GB! That is way too big. We don't want to create that matrix. On the other hand, we see that we only have about 1 million ratings, which would be around 8 MB ($10^6$ numbers $\\times$ at 8 bytes per double precision floating point number). Much more manageable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_X(ratings,n,d,user_key=\"user\",item_key=\"item\"):\n",
    "    user_mapper = dict(zip(np.unique(ratings[user_key]), list(range(n))))\n",
    "    item_mapper = dict(zip(np.unique(ratings[item_key]), list(range(d))))\n",
    "\n",
    "    user_inverse_mapper = dict(zip(list(range(n)), np.unique(ratings[user_key])))\n",
    "    item_inverse_mapper = dict(zip(list(range(d)), np.unique(ratings[item_key])))\n",
    "\n",
    "    user_ind = [user_mapper[i] for i in ratings[user_key]]\n",
    "    item_ind = [item_mapper[i] for i in ratings[item_key]]\n",
    "\n",
    "    X = sparse_matrix((ratings[\"rating\"], (user_ind, item_ind)), shape=(n,d))\n",
    "    \n",
    "    return X, user_mapper, item_mapper, user_inverse_mapper, item_inverse_mapper, user_ind, item_ind\n",
    "\n",
    "X, user_mapper, item_mapper, user_inverse_mapper, item_inverse_mapper, user_ind, item_ind = create_X(ratings, n, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(714791, 105984)\n",
      "993490\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(X.shape) # should be number of users by number of items\n",
    "print(X.nnz)   # number of nonzero elements -- should equal number of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7947920"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.data.nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Above: verifying our estimate of 8 MB to store sparse `X`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1\n",
    "rubric={reasoning:2}\n",
    "\n",
    "Find the following items:\n",
    "\n",
    "1. the item with the most reviews\n",
    "2. the item with the most total stars\n",
    "3. the item with the highest average stars\n",
    "\n",
    "Then, find the names of these items by looking them up with the url https://www.amazon.com/dp/ITEM_ID, where `ITEM_ID` is the id of the item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.com/dp/B00CFM0P7Y\n"
     ]
    }
   ],
   "source": [
    "url_amazon = \"https://www.amazon.com/dp/%s\"\n",
    "\n",
    "# example:\n",
    "print(url_amazon % 'B00CFM0P7Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the item with the most reviews:Classic Accessories 73942 Veranda Grill Cover\n",
      "https://www.amazon.com/dp/B000HCLLMM\n",
      "the item with the most total stars:Classic Accessories 73942 Veranda Grill Cover\n",
      "https://www.amazon.com/dp/B000HCLLMM\n",
      "the item with the highest average stars:Primal Grill with Steven Raichlen, Volume One DVD\n",
      "https://www.amazon.com/dp/0981850006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 35.,  11.,  10., ...,  30.,  25.,  25.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "# 1.1\n",
    "# the item with most reviews\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "user,item = X.nonzero()\n",
    "N = len(user)\n",
    "Nreview_item = Counter(item).most_common()\n",
    "MaxReview = Nreview_item[0]\n",
    "\n",
    "print(\"the item with the most reviews:Classic Accessories 73942 Veranda Grill Cover\")\n",
    "print(url_amazon % item_inverse_mapper[MaxReview[0]])\n",
    "\n",
    "# the item with the most total stars\n",
    "# the item with the highest average stars\n",
    "sumstars = np.zeros(d)\n",
    "mean = np.zeros(d)\n",
    "\n",
    "for i in range(d):\n",
    "    tt = X[:,i].nonzero()\n",
    "    ttemp = X[ tt[0],i ]\n",
    "    sumstars[i] = np.sum(ttemp)\n",
    "    mean[i] = sumstars[i]/ len(tt[0])\n",
    "  \n",
    "# MaxTotal = Nreview_item [ np.argmax(temp) ][0]\n",
    "MaxTotal = np.argmax(sumstars)\n",
    "print(\"the item with the most total stars:Classic Accessories 73942 Veranda Grill Cover\")\n",
    "print(url_amazon % item_inverse_mapper[MaxTotal])\n",
    "\n",
    "\n",
    "MaxMean = np.argmax(mean)\n",
    "print(\"the item with the highest average stars:Primal Grill with Steven Raichlen, Volume One DVD\")\n",
    "print(url_amazon % item_inverse_mapper[MaxMean])\n",
    "\n",
    "# save the sumstars matrix \n",
    "from tempfile import TemporaryFile\n",
    "outfile = TemporaryFile()\n",
    "np.save(outfile, sumstars)\n",
    "outfile.seek(0) # Only needed here to simulate closing & reopening file\n",
    "np.load(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2\n",
    "rubric={reasoning:2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the following histograms \n",
    "\n",
    "1. The number of ratings per user\n",
    "2. The number of ratings per item\n",
    "3. The ratings themselves\n",
    "\n",
    "For the first two, use\n",
    "```\n",
    "plt.yscale('log', nonposy='clip')\n",
    "``` \n",
    "to put the histograms on a log-scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved as '..\\figs\\The number of ratings per user.png'\n",
      "Figure saved as '..\\figs\\The number of ratings per item.png'\n",
      "Figure saved as '..\\figs\\The number of of that rating.png'\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEWCAYAAABG030jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4Jakyvx/VSngACD2VZsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcaacf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEWCAYAAAC0Q+rDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDzBgvTCu01eOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21cdd8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZGNmZqVzsjEzs9I52ZiZWen+P+H6/HXATT0eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21c81f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "user,item = X.nonzero()\n",
    "N = len(user)\n",
    "Nreview_item = Counter(item).most_common()\n",
    "Nreview_user = Counter(user).most_common()\n",
    "\n",
    "\n",
    "FIGS_DIR = 'figs'\n",
    "def savefig(fname, verbose=True):\n",
    "    path = os.path.join('..', FIGS_DIR, fname)\n",
    "    plt.savefig(path)\n",
    "    if verbose:\n",
    "        print(\"Figure saved as '{}'\".format(path))\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist( user )\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.title(\"The number of ratings per user\")\n",
    "plt.xlabel(\"user\")\n",
    "plt.ylabel(\"The number of ratings\")\n",
    "savefig('The number of ratings per user.png' )\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist( item )\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.title(\"The number of ratings per item\")\n",
    "plt.xlabel(\"item\")\n",
    "plt.ylabel(\"The number of ratings\")\n",
    "savefig('The number of ratings per item.png' )\n",
    "\n",
    "Rat = X[user,item]\n",
    "Rat_array = np.squeeze(np.asarray(Rat)) # transform a matrix into array\n",
    "Ratings = Rat_array.astype(int) # transform a float array into int array\n",
    "fig = plt.figure()\n",
    "plt.hist( Ratings )\n",
    "plt.title(\"The number of different ratings\")\n",
    "plt.xlabel(\"rating\")\n",
    "plt.ylabel(\"The number of that rating\")\n",
    "savefig('The number of of that rating.png' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Use scikit-learn's [NearestNeighbors](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html) object (which uses Euclidean distance by default) to find the 5 items most similar to [Brass Grill Brush 18 Inch Heavy Duty and Extra Strong, Solid Oak Handle](https://www.amazon.com/dp/B00CFM0P7Y). \n",
    "\n",
    "The code block below grabs the column of `X` associated with the grill brush. The mappers take care of going back and forther between the IDs (like `B00CFM0P7Y`) and the indices of the sparse array (0,1,2,...).\n",
    "\n",
    "Note: keep in mind that `NearestNeighbors` is for taking neighbors across rows, but here we're working across columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.com/dp/B00CFM0P7Y\n"
     ]
    }
   ],
   "source": [
    "grill_brush = \"B00CFM0P7Y\"\n",
    "grill_brush_ind = item_mapper[grill_brush]\n",
    "grill_brush_vec = X[:,grill_brush_ind]\n",
    "\n",
    "print(url_amazon % grill_brush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind the 5 items most similar to Brass Grill Brush are:\n",
      "https://www.amazon.com/dp/B00CFM0P7Y\n",
      "https://www.amazon.com/dp/B00IJB5MCS\n",
      "https://www.amazon.com/dp/B00IJB4MLA\n",
      "https://www.amazon.com/dp/B00EXE4O42\n",
      "https://www.amazon.com/dp/B00743MZCM\n",
      "https://www.amazon.com/dp/B00HVXQY9A\n",
      "The first one is the grill brush itself. To find 5 items most similar to this grill brush, we need to set 'n_neighbour = 6'\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "Xtranspose = np.transpose(X)\n",
    "\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=6).fit(Xtranspose)\n",
    "distances, indices = neigh.kneighbors(np.transpose(grill_brush_vec))\n",
    "\n",
    "print(\"ind the 5 items most similar to Brass Grill Brush are:\")  \n",
    "for i in range(6):\n",
    "    print(url_amazon % item_inverse_mapper[indices[0][i]])\n",
    "    \n",
    "print(\"The first one is the grill brush itself. To find 5 items most similar to this grill brush, we need to set 'n_neighbour = 6'\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The items which are most similar to Brass Grill Brush are:\n",
    "1. Mr Grill - 18\" Luxury Oak Barbecue Spatula / Turner\n",
    "2. GrillHogs Basting Mop with Replacement Head, 18 Inch Handle with Machine Washable Heads\n",
    "3. Syndicate Sales 9 1/2\" Catalina Bowl, Black\n",
    "4. and 5. are not found by the website.\n",
    "\n",
    "We can find some patterns. They are all related to barbecueã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Using cosine similarity instead of Euclidean distance in `NearestNeighbors`, find the 5 products most similar to `B00CFM0P7Y`.\n",
    "\n",
    "Same as before, The first one is the grill brush itself. \n",
    "\n",
    "To find 5 items most similar to this grill brush, we need to set 'n_neighbour = 6'.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind the 5 items most similar to Brass Grill Brush are:\n",
      "https://www.amazon.com/dp/B00CFM0P7Y\n",
      "https://www.amazon.com/dp/B00IJB5MCS\n",
      "https://www.amazon.com/dp/B00IJB8F3G\n",
      "https://www.amazon.com/dp/B00IJB4MLA\n",
      "https://www.amazon.com/dp/B00EF45AHU\n",
      "https://www.amazon.com/dp/B00EF3YF0Y\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "neigh = NearestNeighbors(n_neighbors=6,metric = 'cosine').fit(Xtranspose)\n",
    "Cosdistances, Cosindices = neigh.kneighbors(np.transpose(grill_brush_vec))\n",
    "\n",
    "print(\"ind the 5 items most similar to Brass Grill Brush are:\")  \n",
    "for i in range(6):\n",
    "    print(url_amazon % item_inverse_mapper[Cosindices[0][i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The items which are most similar to Brass Grill Brush are:\n",
    "1. Mr Grill - 18\" Luxury Oak Barbecue Spatula / Turner\n",
    "2. GrillHogs Luxury Barbecue Grill Tongs 16 Inch, Oak and Stainless Steel\n",
    "3. GrillHogs Basting Mop with Replacement Head, 18 Inch Handle with Machine Washable Heads\n",
    "4. GrillHogs Marinade Injector Stainless Steel with 3 Marinade Needles\n",
    "5. Mr Grill Silicone Oven Gloves Heat Resistant to 425Â°F / 218Â°C - Slip Resistant - Unlined and Dishwasher Washable\n",
    "\n",
    "We can find some patterns. They are all related to barbecue.\n",
    "In addition, plus the Brass Grill Brush, there are 4 items for GrillHoga, and 2 items from Mr.Grill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5\n",
    "rubric={reasoning:2}\n",
    "\n",
    "For each of the two metrics, compute the compute the total popularity (total stars) of each of the 5 items and report it. Do the results make sense given what we discussed in class about Euclidean distance vs. cosine similarity? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total popularity (total stars) of each of the 5 items(except the Brass Grill Brush itself) are:\n",
      "Euclidean distance 486.0\n",
      "Cosine similarity 1733.0\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "EuclidStar = 0\n",
    "CosStar = 0\n",
    "for i in range(5):\n",
    "    Eu = X[ :,indices[0][i+1] ].data\n",
    "    EuclidStar = EuclidStar + sum(Eu)\n",
    "    Cos = X[ :,Cosindices[0][i+1] ].data\n",
    "    CosStar = CosStar + sum(Cos)\n",
    "    \n",
    "print(\"the total popularity (total stars) of each of the 5 items(except the Brass Grill Brush itself) are:\")\n",
    "print(\"Euclidean distance\", EuclidStar)\n",
    "print(\"Cosine similarity\", CosStar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From the results, the total stars of cosine similarity is much larger than Euclidean distance.\n",
    "\n",
    "Cosine similarity measures the angle between vectors (thus not taking into regard their weight or magnitude),\n",
    "while Euclidean distance measures the distance.\n",
    "\n",
    "When the magnitude of the vectors does not matter, Cosine similarity makes more sense, like text data represented by word counts. If a word occurs more times in essay 'A' only because essay 'A' has a longer length, cosine similarity will correct this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6\n",
    "rubric={reasoning:3}\n",
    "\n",
    "PCA gives us an approximation $X \\approx ZW$ where the rows of $Z$ contain a length-$k$ latent feature vectors for each user and the columns of $W$ contain a length-$k$ latent feature vectors for each item.\n",
    "\n",
    "Another strategy for finding similar items is to run PCA and then search for nearest neighbours with Euclidean distance in the latent feature space, which is hopefully more meaningful than the original \"user rating space\". In other words, we run nearest neighbors on the columns of $W$. Using $k=10$ and scikit-learn's [TruncatedSVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html) to perform the dimensionality reduction, find the 5 nearest neighbours to the grill brush using this method. You can access $W$ via the `components_` field of the `TruncatedSVD` object, after you fit it to the data. \n",
    "\n",
    "Briefly comment on your results.\n",
    "\n",
    "Implementation note: when you call on `NearestNeighbors.kneighbors`, it expects the input to be a 2D array. There's some weirdness here because `X` is a scipy sparse matrix but your `W` will be a dense matrix, and they behave differently in subtle ways. If you get an error like \"Expected 2D array, got 1D array instead\" then this is your problem: a column of `W` is technically a 1D array but a column of `X` has dimension $1\\times n$, which is technically a 2D array. You can take a 1D numpy array and add an extra first dimension to it with `array[None]`.\n",
    "\n",
    "Conceptual note 1: We are using the \"truncated\" rather than full SVD since a full SVD would involve dense $d\\times d$ matrices, which we've already established are too big to deal with. And then we'd only use the first $k$ rows of it anyway. So a full SVD would be both impossible and pointless.\n",
    "\n",
    "Conceptual note 2: as discussed in class, there is a problem here, which is that we're not ignoring the missing entries. You could get around this by optimizing the PCA objective with gradient descent, say using `findMin` from previous assignments. But we're just going to ignore that for now, as the assignment seems long enough as it is (or at least it's hard for me to judge how long it will take because it's new)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 items most similar to Brass Grill Brush are:\n",
      "https://www.amazon.com/dp/B00CFM0P7Y\n",
      "https://www.amazon.com/dp/B000MVLB8W\n",
      "https://www.amazon.com/dp/B000H1SJ8C\n",
      "https://www.amazon.com/dp/B001VNC3Q4\n",
      "https://www.amazon.com/dp/B000X9BNG8\n",
      "https://www.amazon.com/dp/B001H1NG1Q\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "# dimensionality reduction\n",
    "\n",
    "svd = TruncatedSVD(n_components=10)\n",
    "svd.fit(X)\n",
    "W = svd.fit(X).components_\n",
    "\n",
    "# we run nearest neighbors on the columns of  W\n",
    "\n",
    "Wt = np.transpose(W)\n",
    "neigh = NearestNeighbors(n_neighbors=6).fit(Wt)\n",
    "\n",
    "# find the correponding reduction of Grill Brush\n",
    "\n",
    "grill_brush = \"B00CFM0P7Y\"\n",
    "grill_brush_ind = item_mapper[grill_brush]\n",
    "Rgrill_brush_vec = W[:,grill_brush_ind]\n",
    "tt = Rgrill_brush_vec.reshape(-1, 1)\n",
    "\n",
    "Rdistances, Rindices = neigh.kneighbors(np.transpose(tt))\n",
    "\n",
    "print(\"The 5 items most similar to Brass Grill Brush are:\")  \n",
    "for i in range(6):\n",
    "    print(url_amazon % item_inverse_mapper[Rindices[0][i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The items which are most similar to Brass Grill Brush are:\n",
    "1. Weber 6417 All-Purpose Summit Drip Pan, 10-Pack\n",
    "2. Weber 3741001 Genesis E-310 Propane Gas Grill, Black\n",
    "3. Classic Accessories Veranda Fire Pit Cover, X-Large, Standing\n",
    "4. Classic Accessories Patio Large BBQ Grill Cover\n",
    "5. Classic Accessories Terrazzo Rectangular/Oval Patio Table Cover - All Weather Protection Outdoor Furniture Cover (58242-EC)\n",
    "\n",
    "We can find some patterns. They are all related to barbecue. \n",
    "\n",
    "However, these 5 items are not directly related to the process of grilling, like the cook tools in previous results. Thay are related items about barbecue in a more broad view. \n",
    "\n",
    "In my opinion, searching for nearest neighbours with Euclidean distance in the latent feature space maybe more practical. Since for a certain user, once he bought one cook tool for grilling meat, he may need other items for BBQ, like Grill cover or Drip pan, instead of buying kinds of cook tools for BBQ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: putting it all together in a CPSC 340 \"mini-project\"\n",
    "rubric={reasoning:25}\n",
    "\n",
    "In this open-ended mini-project, you'll explore the [UCI default of credit card clients data set](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients). There are 30,000 examples and 24 features, and the goal is to estimate whether a person will default (fail to pay) their credit card bills; this column is labeled \"default payment next month\" in the data. The rest of the columns can be used as features. \n",
    "\n",
    "\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Download the data set and load it in. Since the data comes as an MS Excel file, I suggest using [`pandas.read_excel`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html) to read it in. See [Lecture 2](https://github.ugrad.cs.ubc.ca/CPSC340-2017W-T2/home/blob/master/lectures/L2.ipynb) for an example of using pandas.\n",
    "2. Perform exploratory data analysis on the data set. Include at least two summary statistics and two visualizations that you find useful, and accompany each one with a sentence explaining it.\n",
    "3. Randomly split the data into train, validation, test sets. The validation set will be used for your experiments. The test set should be saved until the end, to make sure you didn't overfit on the validation set. You are welcome to use scikit-learn's [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), which takes care of both shuffling and splitting. \n",
    "4. Try scikit-learn's [DummyClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) as a baseline model.\n",
    "5. Try logistic regression as a first real attempt. Make a plot of train/validation error vs. regularization strength. Whatâ€™s the lowest validation error you can get?\n",
    "6. Explore the features, which are described on the UCI site. Explore preprocessing the features, in terms of transforming non-numerical variables, feature scaling, change of basis, etc. Did this improve your results?\n",
    "7. Try 3 other models aside from logistic regression, at least one of which is a neural network. Can you beat logistic regression? (For the neural net(s), the simplest choice would probably be to use scikit-learn's [MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html), but you are welcome to use any software you wish. )\n",
    "8. Make some attempts to optimize hyperparameters for the models you've tried and summarize your results. In at least one case you should be optimizing multiple hyperparameters for a single model. I won't make it a strict requirement, but I recommend checking out one of the following (the first two are simple scikit-learn tools, the latter two are much more sophisticated algorithms and require installing new packages): \n",
    "  - [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)   \n",
    "  - [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "  - [hyperopt-sklearn](https://github.com/hyperopt/hyperopt-sklearn)\n",
    "  - [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize)\n",
    "9. Explore feature selection for this problem. What are some particularly relevant and irrelevant features? Can you improve on your original logistic regression model if you first remove some irrelevant features?\n",
    "10. Take your best model overall. Train it on the combined train/validation set and run it on the test set once. Does the test error agree fairly well with the validation error from before? Do you think youâ€™ve had issues with optimization bias? Report your final test error directly in your README.md file as well as in your report.\n",
    "\n",
    "**Submission format:**\n",
    "Your submission should take the form of a \"report\" that includes both code and an explanation of what you've done. You don't have to include everything you ever tried - it's fine just to have your final code - but it should be reproducible. For example, if you chose your hyperparameters based on some hyperparameter optimization experiment, you should leave in the code for that experiment so that someone else could re-run it and obtain the same hyperparameters, rather than mysteriously just setting the hyperparameters to some (carefully chosen) values in your code.\n",
    "\n",
    "**Assessment:**\n",
    "We plan to grade and fairly leniently. We don't have some secret target accuracy that you need to achieve to get a good grade. You'll be assessed on demonstration of mastery of course topics, clear presentation, and the quality of your analysis and results. For example, if you write something like, \"And then I noticed the model was overfitting, so I decided to stop using regularization\" - then, well, that's not good. If you just have a bunch of code and no text or figures, that's not good. If you do a bunch of sane things and get a lower accuracy than your friend, don't sweat it.\n",
    "\n",
    "**And...**\n",
    "This style of this \"project\" question is different from other assignments. It'll be up to you to decide when you're \"done\" -- in fact, this is one of the hardest parts of real projects. But please don't spend WAY too much time on this... perhaps \"a few hours\" (2-6 hours???) is a good guideline for a typical submission. Of course if you're having fun you're welcome to spend as much time as you want! But, if so, don't do it out of perfectionism... do it because you're learning and enjoying it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE AND REPORT HERE, IN A SENSIBLE FORMAT\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from skimage.io import imread, imshow\n",
    "\n",
    "# 1. read the data\n",
    "\n",
    "filename = \"default of credit card clients.xls\"\n",
    "\n",
    "with open(os.path.join(\"..\", \"data\", filename), \"rb\") as f:\n",
    "    Xx = pd.read_excel(f)\n",
    "Xx.head()\n",
    "\n",
    "nn,dd = Xx.shape\n",
    "tt = Xx.values\n",
    "n = nn-1\n",
    "d = dd-1\n",
    "\n",
    "Y = Xx['Y'][1:nn]    # the binary label vector\n",
    "X = np.zeros((n,d)) # the data set\n",
    "for i in range(d):\n",
    "    X[:,i] = tt[1:n+1,i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perform exploratory data analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of BILL_AMT1~6 over all clients is 46197.98216\n",
      "The average of PAY_AMT1~6 over all clients is 5287.178\n",
      "The largest age over all clients is 79.0\n",
      "The smallest age over all clients is 21.0\n"
     ]
    }
   ],
   "source": [
    "# 2.Perform exploratory data analysis \n",
    "\n",
    "# summary statistics\n",
    "\n",
    "# Bill_AMT1~6 and Pay_AMT1~average\n",
    "\n",
    "bill_mean = np.mean(X[:,11:16])\n",
    "pay_mean = np.mean(X[:,17:22])\n",
    "age_max = np.max(X[:,4])\n",
    "age_min = np.min(X[:,4])\n",
    "\n",
    "print(\"The average of BILL_AMT1~6 over all clients is\",bill_mean)\n",
    "print(\"The average of PAY_AMT1~6 over all clients is\",pay_mean)\n",
    "print(\"The largest age over all clients is\",age_max)\n",
    "print(\"The smallest age over all clients is\",age_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\figs\\\\The histogram of Education.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-34e0820cd484>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Education\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Frequency\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The histogram of Education.png'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-34e0820cd484>\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(fname, verbose)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'..'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFIGS_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Figure saved as '{}'\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(self, fname, **kwargs)\u001b[0m\n\u001b[0;32m   1812\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1814\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[0;32m   2257\u001b[0m                 \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2258\u001b[0m                 \u001b[0mbbox_inches_restore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2259\u001b[1;33m                 **kwargs)\n\u001b[0m\u001b[0;32m   2260\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2261\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m             \u001b[0mfilename_or_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    513\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\figs\\\\The histogram of Education.png'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEZCAYAAABFFVgWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x298523cf048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# two visualizations\n",
    "\n",
    "FIGS_DIR = 'figs'\n",
    "def savefig(fname, verbose=True):\n",
    "    path = os.path.join('..', FIGS_DIR, fname)\n",
    "    plt.savefig(path)\n",
    "    if verbose:\n",
    "        print(\"Figure saved as '{}'\".format(path))\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(X[:,2])\n",
    "#plt.yscale('log', nonposy='clip')\n",
    "plt.title(\"The histogram of Education\")\n",
    "plt.xlabel(\"Education\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "savefig('The histogram of Education.png' )\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(X[:,4])\n",
    "#plt.yscale('log', nonposy='clip')\n",
    "plt.title(\"The histogram of Age\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "savefig('The_histogram_of_age.png' )\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(X[:,2],X[:,0])\n",
    "plt.title(\"The scatter plot of Education vs limit_BAL\")\n",
    "plt.xlabel(\"Education\")\n",
    "plt.ylabel(\"limit_BAL\")\n",
    "savefig('The scatter plot of Education vs limit_BAL.png' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the first two figures, we can get that the education level of most clients are 1,2 and 3, and most clients are 20~40 years old.<br>\n",
    "From the last picture, clients without education will never get the LIMIT_BAL larger than 400,000.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Randomly split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = np.asarray(range(n))\n",
    "np.random.shuffle(index)\n",
    "Xrand = X[index,:]\n",
    "yrand = Y[index]\n",
    "Yrand = np.array(list(yrand[:]), dtype=np.float)\n",
    "# Split training data into raining, test and validation sets\n",
    "Xtrain = Xrand[0:n//3]\n",
    "ytrain = Yrand[0:n//3]\n",
    "\n",
    "Xtest = Xrand[n//3:2*(n//3)]\n",
    "ytest = Yrand[n//3:2*(n//3)]\n",
    "\n",
    "Xvalid = Xrand[2*(n//3): n]\n",
    "yvalid = Yrand[2*(n//3): n]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DummyClassifier as a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier validation error: 0.222\n"
     ]
    }
   ],
   "source": [
    "## 4. DummyClassifier as a baseline model\n",
    "from sklearn.dummy import DummyClassifier\n",
    "base = DummyClassifier(strategy='most_frequent')\n",
    "base.fit(Xtrain, ytrain)\n",
    "y_hat = base.predict(Xvalid)\n",
    "error = np.mean(y_hat != yvalid)\n",
    "\n",
    "print(\"DummyClassifier validation error: %.3f\" % error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.  Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-33f63dbdbe3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mEtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mytrain\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mEvalid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0myvalid\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXvalid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[1;32m-> 1216\u001b[1;33m                          order=\"C\")\n\u001b[0m\u001b[0;32m   1217\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'O'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 44\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "C = 100\n",
    "Etrain = np.zeros(C)\n",
    "Evalid = np.zeros(C)\n",
    "\n",
    "for c in range(1,100):\n",
    "    model = LogisticRegression(fit_intercept=True, C = 1/c)\n",
    "    model.fit(Xtrain,ytrain)\n",
    "    Etrain[c] = np.mean( ytrain != model.predict(Xtrain) )\n",
    "    Evalid[c] = np.mean( yvalid != model.predict(Xvalid) ) \n",
    "    '''\n",
    "    print(\"scikit-L2 with lambda = \", c ) \n",
    "    print(\"Training error %.3f\" , Etrain[c])\n",
    "    print(\"Validation error %.3f\" , Evalid[c])\n",
    "    print(\"# nonZeros: %d\\n\" % (model.coef_ != 0).sum() )\n",
    "    '''\n",
    "\n",
    "FIGS_DIR = 'figs'\n",
    "def savefig(fname, verbose=True):\n",
    "    path = os.path.join('..', FIGS_DIR, fname)\n",
    "    plt.savefig(path)\n",
    "    if verbose:\n",
    "        print(\"Figure saved as '{}'\".format(path))\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(Etrain[1:])\n",
    "plt.plot(Evalid[1:])\n",
    "plt.title(\"Train/validation error vs. regularization strength\")\n",
    "plt.xlabel(\"regularization strength\")\n",
    "plt.ylabel(\"Train/validation error\")\n",
    "savefig('Etrain_Evalid.png' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is strange that training error and validation error keep the same when regularization strength changes. Training error keeps at 0.2242. Validation error keeps at 0.2202."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Explore the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2ec2ca0ce07b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mrEtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mytrain\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrXtrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mrEvalid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0myvalid\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrXvalid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[1;32m-> 1216\u001b[1;33m                          order=\"C\")\n\u001b[0m\u001b[0;32m   1217\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'O'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 44\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(Xtrain)  \n",
    "rXtrain = scaler.transform(Xtrain)  \n",
    "# apply same transformation to test data\n",
    "rXtest = scaler.transform(Xtest) \n",
    "rXvalid = scaler.transform(Xvalid) \n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "C = 100\n",
    "rEtrain = np.zeros(C)\n",
    "rEvalid = np.zeros(C)\n",
    "\n",
    "for i in range(1,100):\n",
    "    c = i\n",
    "    model = LogisticRegression(fit_intercept=True, C = 1/c)\n",
    "    model.fit(rXtrain,ytrain)\n",
    "    rEtrain[i] = np.mean( ytrain != model.predict(rXtrain) )\n",
    "    rEvalid[i] = np.mean( yvalid != model.predict(rXvalid) ) \n",
    "    \n",
    "print(\"After feature scaling, Logistic Regression (sklearn) validation error: %.3f\" % rEvalid[1])\n",
    "\n",
    "FIGS_DIR = 'figs'\n",
    "def savefig(fname, verbose=True):\n",
    "    path = os.path.join('..', FIGS_DIR, fname)\n",
    "    plt.savefig(path)\n",
    "    if verbose:\n",
    "        print(\"Figure saved as '{}'\".format(path))\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(rEtrain[1:])\n",
    "plt.plot(rEvalid[1:])\n",
    "plt.title(\"Train/validation error vs. regularization strength\")\n",
    "plt.xlabel(\"regularization strength\")\n",
    "plt.ylabel(\"Train/validation error\")\n",
    "savefig('Etrain_Evalid_feature_scaling.png' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling:<br>\n",
    "I center the data around 0 with Scikit-Learnâ€™s preprocessing module.<br>\n",
    "\n",
    "After scaling, the error gets sightly improved.Training error becomes 0.2196. Validation error becomes 0.2193."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Try 3 other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (sklearn) validation error: 0.238\n",
      "After feature scaling, Random Forest (sklearn) validation error: 0.237\n",
      "Naive Bayes (sklearn) validation error: 0.219\n",
      "After feature scaling, Naive Bayes (sklearn) validation error: 0.219\n",
      "Neural Network(sklearn) validation error: 0.262\n",
      "After feature scaling, Neural Network(sklearn) validation error: 0.222\n"
     ]
    }
   ],
   "source": [
    "## 7. Try 3 other models\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from skimage.io import imread, imshow, imsave\n",
    "\n",
    "\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(Xtrain, ytrain)\n",
    "y_pred = model.predict(Xvalid)\n",
    "v_error = np.mean(y_pred != yvalid)\n",
    "print(\"Random Forest (sklearn) validation error: %.3f\" % v_error)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(rXtrain, ytrain)\n",
    "y_pred = model.predict(rXvalid)\n",
    "v_error = np.mean(y_pred != yvalid)\n",
    "print(\"After feature scaling, Random Forest (sklearn) validation error: %.3f\" % v_error)\n",
    "\n",
    "## Naive Bayes\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(Xtrain, ytrain)\n",
    "y_pred = model.predict(Xvalid)\n",
    "v_error = np.mean(y_pred != yvalid)\n",
    "print(\"Naive Bayes (sklearn) validation error: %.3f\" % v_error)\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(rXtrain, ytrain)\n",
    "y_pred = model.predict(rXvalid)\n",
    "v_error = np.mean(y_pred != yvalid)\n",
    "print(\"After feature scaling, Naive Bayes (sklearn) validation error: %.3f\" % v_error)\n",
    "\n",
    "## Neural Network\n",
    "\n",
    "#nn = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(15,), random_state=1)\n",
    "nn = MLPClassifier(random_state=4)\n",
    "nn.fit( Xtrain , ytrain)\n",
    "y_predNN = nn.predict(Xvalid)\n",
    "v_error = np.mean(y_predNN != yvalid)\n",
    "print(\"Neural Network(sklearn) validation error: %.3f\" % v_error)\n",
    "\n",
    "nn.fit(rXtrain, ytrain)\n",
    "y_predNN2 = nn.predict(rXvalid)\n",
    "v_error = np.mean(y_predNN2 != yvalid)\n",
    "print(\"After feature scaling, Neural Network(sklearn) validation error: %.3f\" % v_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expect the nerural network will work much better than the previous 4 methods. But the reseluts shows that actually, they all work not very well with validation error at around 0.2.<br>\n",
    "\n",
    "I think the reasons may lay in the exploring feature process and the inappropriate hyperparameters. <br>\n",
    "\n",
    "However, what I learned is that for neural network, feature scaling is essential which will improve performance, like decrease the validation error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Explore feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use L0-Regularization to do the feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Very short answer questions\n",
    "rubric={reasoning:7}\n",
    "\n",
    "1. Why is it difficult for a standard collaborative filtering model to make good predictions for new items?\n",
    "2. Consider a fully connected neural network with layer sizes (10,20,20,5); that is, the input dimensionality is 10, there are two hidden layers each of size 20, and the output dimensionality is 5. How many parameters does the network have, including biases?\n",
    "3. Why do we need nonlinear activation functions in neural networks?\n",
    "4. Assuming we could globally minimize the neural network objectve, how does the depth of a neural network affect the fundamental trade-off?\n",
    "5. List 3 forms of regularization we use to prevent overfitting in neural networks.\n",
    "6. Assuming we could globally minimize the neural network objectve, how would the size of the filters in a convolutational neural network affect the fundamental trade-off?\n",
    "7. Why do people say convolutional neural networks just a special case of a fully-connected (regular) neural networks? What does this imply about the number of learned parameters?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "_Answer:_\n",
    "\n",
    "1. In Netflix prize, collaborative filtering only looks at ratings to make predictions, not features of movies/users. However, new items may have few or no ratings available. Hence, it is hard to predict on new items.\n",
    "\n",
    "2. In the learning process, we want to find the weights and biases. So the parameters include weights and biases. <br>\n",
    "From the first layer to second layer, we have $10\\times20$ weights and 20 biases.<br>\n",
    "From the second layer to third layer, we have $20\\times20$ weights and 20 biases.<br>\n",
    "From the third layer to last layer, we have $5\\times20$ weights and 5 biases.<br>\n",
    "Overall, we have 700 weights and 45 biases.\n",
    "\n",
    "3. Without introducing non-linear activation function, all we have is the linear latent-factor model with linear regression. This is just a linear model, and we cannot deal with non-linear situation with this model.<br>\n",
    "Therefore, we need non-linear function to increase flexibility.\n",
    "\n",
    "4. The depth of a neural network is subject to the fundamental trade-off.<br>\n",
    "As the depth increases, the training error will go down, while the approximation error will go up.\n",
    "\n",
    "5. The standard regularization.<br>\n",
    "Early stopping.<br>\n",
    "Dropout.<br>\n",
    "\n",
    "6. As the width incerases, the training error will go down, while the approximation error will go up.\n",
    "\n",
    "7. Because in convolutional neural network, it firstly has the usual neural network layer with unrestricted W, and then restricts W to results of several convolutions.<br>\n",
    "CNN drastically reduces the number of parameters.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
